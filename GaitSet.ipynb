{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GaitSet Implements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as tordata\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from network.network import SetNet\n",
    "from network.network_layer import *\n",
    "from network.triplet_loss import *\n",
    "from utils.triplet_sampler import *\n",
    "from utils.data_load import *\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = load_OU_ISIR('./data/OU_ISIR/npy/', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_sampler = TripletSampler(train_dataset, [16, 2])\n",
    "\n",
    "train_loader = tordata.DataLoader(dataset=train_dataset, batch_sampler=triplet_sampler, collate_fn=collate_fnn)\n",
    "test_loader = tordata.DataLoader(dataset=test_dataset, batch_size=1, sampler=tordata.sampler.SequentialSampler(test_dataset), collate_fn=collate_fnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = SetNet(128).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = TripletLoss(8, 0.2).to(device)\n",
    "optimizer = optim.Adam([{'params':encoder.parameters()},], lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_iter = 20000\n",
    "all_losses = []\n",
    "\n",
    "pool = mp.Pool(processes=6)\n",
    "\n",
    "s_time = datetime.now()\n",
    "for i, (seqs, view, label) in enumerate(train_loader):\n",
    "    \n",
    "    feature = encoder(seqs)\n",
    "    \n",
    "    tmp_label_set = list(train_dataset.set_label)\n",
    "    \n",
    "    target_label = [tmp_label_set.index(l) for l in label]\n",
    "    target_label = Variable(torch.IntTensor(target_label)).to(device)\n",
    "    \n",
    "    triplet_feature = feature.permute(1, 0, 2).contiguous()\n",
    "    triplet_label = target_label.unsqueeze(0).repeat(triplet_feature.size(0), 1)\n",
    "    \n",
    "    hard_loss, dist_mean = criterion(triplet_feature, triplet_label)\n",
    "    \n",
    "    loss = hard_loss.mean()\n",
    "    \n",
    "    if loss > 1e-9:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "\n",
    "    if (i+1) % 100 == 0:\n",
    "        print('Step [{}], Elapsed Time [{}], Loss [{}]'.format(i+1, datetime.now() - s_time, loss))\n",
    "        all_losses.append(loss)\n",
    "        s_time = datetime.now()\n",
    "        \n",
    "    #if (i+1) % 500 == 0:\n",
    "    #    pca = TSNE(2)\n",
    "    #    pca_feature = pca.fit_transform( feature.contiguous().view(feature.size(0), -1).data.cpu().numpy() )\n",
    "    #    for i in range(16):\n",
    "    #        plt.scatter(pca_feature[i:i+1, 0], pca_feature[i:i+1, 1], label=label[i])\n",
    "    #\n",
    "    #    plt.show()\n",
    "        \n",
    "    if (i+1) == total_iter:\n",
    "        torch.save(encoder.state_dict(), os.path.join('./checkpoint/','OU_ISIR_Encoder_1.ptm'))\n",
    "        torch.save(optimizer.state_dict(), os.path.join('./checkpoint/','OU_ISIR_Optimizer_1.ptm'))\n",
    "        break\n",
    "        \n",
    "    if (i+1) == (total_iter // 2):\n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] = 1e-6\n",
    "        \n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawLoss(loss_dict):\n",
    "    plt.style.use(['ggplot'])\n",
    "    \n",
    "    for key, value in loss_dict.items():\n",
    "        x = np.arange(len(loss_dict[key]))\n",
    "        plt.plot(x, loss_dict[key], label=key)\n",
    "    \n",
    "    plt.xlabel(\"train step\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawLoss({'Loss':all_losses})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.load_state_dict(torch.load('./checkpoint/OU_ISIR_Encoder.ptm'))\n",
    "optimizer.load_state_dict(torch.load('./checkpoint/OU_ISIR_Optimizer.ptm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = mp.Pool(processes=6)\n",
    "\n",
    "feature_list = []\n",
    "view_list = []\n",
    "label_list = []\n",
    "\n",
    "s_time = datetime.now()\n",
    "for i, (seqs, view, label) in enumerate(test_loader):\n",
    "\n",
    "    feature = encoder(seqs)\n",
    "    \n",
    "    n, num_bins, _ = feature.size()\n",
    "    feature_list.append(feature.view(n, -1).data.cpu().numpy())\n",
    "    view_list += view\n",
    "    label_list += label\n",
    "    \n",
    "test = np.concatenate(feature_list, 0)\n",
    "        \n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = TSNE(2, perplexity=40, learning_rate=100, verbose=True, random_state=0)\n",
    "\n",
    "aa = torch.tensor(feature_list)\n",
    "pca_feature = pca.fit_transform( aa.contiguous().view(aa.size(0), -1).data.cpu().numpy() )\n",
    "\n",
    "xs = pca_feature[:,0]\n",
    "ys = pca_feature[:,1]\n",
    "\n",
    "plt.scatter(xs, ys, c = label_list)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda_dist(x, y):\n",
    "    x = torch.from_numpy(x).cuda()\n",
    "    y = torch.from_numpy(y).cuda()\n",
    "    dist = torch.sum(x ** 2, 1).unsqueeze(1) + torch.sum(y ** 2, 1).unsqueeze(\n",
    "        1).transpose(0, 1) - 2 * torch.matmul(x, y.transpose(0, 1))\n",
    "    dist = torch.sqrt(F.relu(dist))\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(feature, view, label):\n",
    "    \n",
    "    label = np.array(label)\n",
    "    view_list = list(set(view))\n",
    "    view_list.sort()\n",
    "    view_num = len(view_list)\n",
    "    sample_num = len(feature)\n",
    "\n",
    "    probe_seq_list = ['00']\n",
    "    gallery_seq_list = ['01']\n",
    "\n",
    "    num_rank = 5\n",
    "    acc = np.zeros([len(probe_seq_list), view_num, view_num, num_rank])\n",
    "    for (p, probe_seq) in enumerate(probe_seq_list):\n",
    "        for gallery_seq in gallery_seq_list:\n",
    "            for (v1, probe_view) in enumerate(view_list):\n",
    "                for (v2, gallery_view) in enumerate(view_list):\n",
    "                    gseq_mask = np.isin(view, [gallery_view])\n",
    "                    gallery_x = feature[gseq_mask, :]\n",
    "                    gallery_y = label[gseq_mask]\n",
    "\n",
    "                    pseq_mask = np.isin(view, [probe_view])\n",
    "                    probe_x = feature[pseq_mask, :]\n",
    "                    probe_y = label[pseq_mask]\n",
    "\n",
    "                    dist = cuda_dist(probe_x, gallery_x)\n",
    "                    idx = dist.sort(1)[1].cpu().numpy()\n",
    "                    acc[p, v1, v2, :] = np.round(\n",
    "                        np.sum(np.cumsum(np.reshape(probe_y, [-1, 1]) == gallery_y[idx[:, 0:num_rank]], 1) > 0,\n",
    "                               0) * 100 / dist.shape[0], 2)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_diag(acc, each_angle=False):\n",
    "    result = np.sum(acc - np.diag(np.diag(acc)), 1) / 10.0\n",
    "    if not each_angle:\n",
    "        result = np.mean(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = evaluation(test, view_list, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = acc[0,:,:,0]\n",
    "\n",
    "res_del_same_view = np.sum(test_acc - np.diag(np.diag(test_acc)), 1) / 13.0\n",
    "res_with_same_view = np.mean(test_acc, 1)\n",
    "\n",
    "print('Without Same View Result')\n",
    "print(res_del_same_view)\n",
    "print(res_del_same_view.mean())\n",
    "print('With Same View Result')\n",
    "print(res_with_same_view)\n",
    "print(res_with_same_view.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
